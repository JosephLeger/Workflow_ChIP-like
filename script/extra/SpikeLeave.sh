#!/usr/bin/env bash

################################################################################################################
### HELP -------------------------------------------------------------------------------------------------------
################################################################################################################
script_name='SpikeLeave.sh'

# Get user id for custom manual pathways
usr=`id | sed -e 's@).*@@g' | sed -e 's@.*(@@g'`

# Text font variables
END='\033[0m'
BOLD='\033[1m'
UDL='\033[4m'

# Show command manual
Help()
{
echo -e "${BOLD}####### PEAKYFINDER MANUAL #######${END}\n\n\
${BOLD}SYNTHAX${END}\n\
	sh ${script_name} [options] <stat_ref> <stat_spike>\n\n\

${BOLD}DESCRIPTION${END}\n\
	Perform spike-in normalization from BAM files using corresponding stat files generated by 3_Bowtie2.sh\n\
	It defines scale factors for each file as the percentage of reads mapped to spike-in genome scaled from 0 to 1.\n\
	Summarized stats reports and thus calculated scale factors are written in a new CSV file before applying normalization.\n\
	Normalized files are exported in .bedgraph and .bw format.\n\
	It creates new folders './Mapped/<ref_model>/BEDGRAPH' and './Mapped/<ref_model>/BW' in which output files are stored.\n\n\

${BOLD}OPTIONS${END}\n\n\
	${BOLD}-N${END} ${UDL}suffix${END}, ${BOLD}N${END}amePattern\n\
		Define a suffix that input files must share to be considered. Allows to exclude BAM files that are unfiltered or unwanted.\n\
		Default = '_filtered'\n\n\
	${BOLD}-O${END} ${UDL}path${END}, ${BOLD}O${END}utputFIlename\n\
		Define file name and path of final summarized stat file.\n\
		Default = <stat_ref_directory>/'Complete_Summary_Stats.csv'\n\n\

${BOLD}ARGUMENTS${END}\n\
	${BOLD}<stat_ref>${END}\n\
		Summary stats file generated by 3_Bowtie2.sh using the reference genome of the model.\n\
		It usually corresponds to 'Mapped/<model>/STAT/Summary_Stats_<model>.csv'.\n\n\
	${BOLD}<spike_ref>${END}\n\
		Summary stats file generated by 3_Bowtie2.sh using the spike-in genome.\n\
		It usually corresponds to 'Mapped/<model>/STAT/Summary_Stats_<spike>.csv'.\n\n\
    
${BOLD}EXAMPLE USAGE${END}\n\
	sh ${script_name} ${BOLD}-N${END} '_spiked' ${BOLD}Mapped/mm39/STAT/Summary_Stats_mm39.csv Mapped/ecoli/STAT/Summary_Stats_ecoli.csv${END}\n"
}

################################################################################################################
### OPTIONS ----------------------------------------------------------------------------------------------------
################################################################################################################

# Set default values
N_arg='_filtered'
O_arg='none'

# Change default values if another one is precised
while getopts ":N:O:" option; do
	case $option in
		N) # NAME OF FILE (SUFFIX)
			N_arg=${OPTARG};;
		O) # OUTPUT FILE
			O_arg=${OPTARG};;
		\?) # Error
			echo "Error : invalid option"
			echo "      Allowed options are [-N|-O]"
			echo "      Enter 'sh ${script_name} help' for more details"
			exit;;
	esac
done

# Deal with options [-N|-O] and arguments [$1|$2]
shift $((OPTIND-1))

# Checking if provided option values are correct
case ${O_arg} in
	NONE|None|none|FALSE|False|false|F|f)
		O_arg="$(dirname ${1})"/Complete_Summary_Stats.csv;;
	*)
		O_arg=${O_arg};;
esac
	
################################################################################################################
### ERRORS -----------------------------------------------------------------------------------------------------
################################################################################################################

if [ $# -eq 1 ] && [ $1 == "help" ]; then
	Help
	exit
elif [ $# -ne 2 ]; then
	# Error if inoccrect number of agruments is provided
	echo "Error synthax : please use following synthax"
	echo "      sh ${script_name} [options] <stat_ref> <stat_spike>"
	exit
elif [ $(ls ${1} 2>/dev/null | wc -l) -lt 1 ]; then
	# Error if provided stat_ref does not exists
	echo "Error : file not found ${1}. Please make sure the provided input file exists."
	exit
elif [ $(ls ${1} 2>/dev/null | wc -l) -lt 1 ]; then
	# Error if provided stat_spike does not exists
	echo "Error : file not found ${2}. Please make sure the provided input file exists."
	exit
fi

################################################################################################################
### SCRIPT -----------------------------------------------------------------------------------------------------
################################################################################################################

## SETUP - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
module load deeptools/3.5.0

# Generate REPORT
echo '#' >> ./0K_REPORT.txt
date >> ./0K_REPORT.txt

Launch()
{
# Launch COMMAND and save report
echo -e "#$ -V \n#$ -cwd \n#$ -S /bin/bash \n""${COMMAND}" | qsub -N "${JOBNAME}" ${WAIT}
echo -e "${JOBNAME}" >> ./0K_REPORT.txt
echo -e "${COMMAND}" | sed 's@^@   \| @' >> ./0K_REPORT.txt
}
WAIT=''

## PREPARE INPUT FILES - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
# Initialize required variables
tmp_scale="$(dirname ${1})"/tmp_scaleFactor.csv
new_vec=()
max=0

# Read all lines in provided spike stat file
sed 1d ${2} | (while IFS=',' read -r file depth mono multi total rate; do
	# Define max value and append new vector corresponding to spike-in percentage
	val=`echo ${rate} | sed -e 's@\%@@g'`
	if (( $(echo "${val} > ${max}" |bc -l) )); then
		max="${val}"
	fi
	new_vec+=(${val})
done
# Initialize scaleFactor.csv file
echo 'scaleFactor' > ${tmp_scale}
# Travel into new_vec, calculate scale factor and append file
scaleFactor=()
for i in ${new_vec[@]}; do
	factor=`printf %.2f $(echo "${i}"/"${max}" | bc -l)`
	echo "${factor}" >> ${tmp_scale}
done
# Creates a new file containing merged columns of interest from both ref and ppike Summary_Stats files
paste -d',' ${1} ${2} ${tmp_scale} | cut -f1,2,3,4,5,6,9,10,11,12,13 -d','> ${O_arg}
)

## SPIKE IN NORMALIZATION - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
# Create output directory
outdir_bdg="$(dirname $(dirname ${1}))"/BEDGRAPH
outdir_bw="$(dirname $(dirname ${1}))"/BIGWIG
mkdir -p ${outdir_bdg}
mkdir -p ${outdir_bw}

# Read all lines in previously generated final stat file
sed 1d ${O_arg} | (while IFS=',' read -r file depth mono_r multi_r total_r rate_r mono_s multi_s total_s rate_s scaleFactor; do
	# Set variables for jobname
	true_file=`echo ${file} | sed -e "s@\.bam@${N_arg}\.bam@g"`
	current_file=`echo ${true_file} | sed -e "s@.*\/@@g" | sed -e 's@\.bam@@g'`
	# Define JOBNAME and COMMAND and launch job
	JOBNAME="SpikeLeave_${current_file}"
	COMMAND="bamCoverage --scaleFactor ${scaleFactor} --outFileFormat 'bedgraph' -b ${true_file} -o ${outdir_bdg}'/'${current_file}_spiked.bedgraph\n\
	bamCoverage --scaleFactor ${scaleFactor} --outFileFormat 'bigwig' -b ${true_file} -o ${outdir_bw}'/'${current_file}_spiked.bw"
	Launch
done
)
